import numpy as np
import scipy as sp
import warnings
from multiprocessing import Process, Queue
from tqdm import tqdm

from .generic_functions import *
from .matrix_operators import sqrtm, invsqrtm, logm, expm

def vech_SCM(X, args):
    """ Serve to compute feature for Covariance only classification.
        We use vech opeartion to save memory space.
        ----------------------------------------------------------------------
        Inputs:
        --------
            * X = a (p, N) array where p is the dimension of data and N the number of samples used for estimation
            * args = (center_vectors) where
                ** center_vectors = boolean to center vectors before computing the SCM

        Outputs:
        ---------
            * ğ± = the feature for classification
        """
    center_vectors = args
    if center_vectors:
        mean = np.mean(X, axis=1)
        mean = mean[:, np.newaxis, :]
        X = X - mean
    return list(vech(SCM(np.squeeze(X))))


def vech_tylerdet(ğ—, args):
    """ Serve to compute feature for Covariance only classification but robust estimation.
        We use vech opeartion to save memory space.
        ----------------------------------------------------------------------
        Inputs:
        --------
            * ğ— = a (p, N) array where p is the dimension of data and N the number
                    of samples used for estimation
            * args = (Ïµ, iter_max) for Tyler estimator, where
                ** Ïµ = tolerance for convergence
                ** iter_max = number of iterations max

        Outputs:
        ---------
            * ğ± = the feature for classification
        """
    Ïµ, iter_max = args
    ğšº, Î´, iteration = tyler_estimator_covariance_normalisedet(np.squeeze(ğ—), Ïµ, iter_max)
    return list(vech(ğšº))


def Wishart_distance(vhğšº_1, vhğšº_2, params=None):
    """ Wishart distance as described in II.B. of:
        P. Formont, F. Pascal, G. Vasile, J. Ovarlez and L. Ferro-Famil, 
        "Statistical Classification for Heterogeneous Polarimetric SAR Images," 
        in IEEE Journal of Selected Topics in Signal Processing, 
        vol. 5, no. 3, pp. 567-576, June 2011.
        doi: 10.1109/JSTSP.2010.2101579
        ----------------------------------------------------------------------
        Inputs:
        --------
            * vhğšº_1 = a (p,) numpy array corresponding to the vech 
                    of the covariance matrix 1
            * vhğšº_2 = a (p,) numpy array corresponding to the vech 
                    of the covariance matrix 2
            * params = scale either 'linear' or anything else for log scale

        Outputs:
        ---------
            * d = the Wishart distance between ğšº_1 and ğšº_2
        """
    ğšº_1 = unvech(vhğšº_1)
    ğšº_2 = unvech(vhğšº_2)
    d = np.log(np.abs(np.linalg.det(ğšº_2))) - np.log(np.abs(np.linalg.det(ğšº_1))) + \
        np.trace(np.linalg.inv(ğšº_2) @ ğšº_1)
    if params=='linear':
        np.exp(np.real(d))
    else:
        return np.real(d)


def Wishart_affinity(vhğšº_1, vhğšº_2, params=None):
    """ Wishart affinity distance obtained as the inverse of Wishart distance
        ----------------------------------------------------------------------
        Inputs:
        --------
            * vhğšº_1 = a (p,) numpy array corresponding to the vech 
                    of the covariance matrix 1
            * vhğšº_2 = a (p,) numpy array corresponding to the vech 
                    of the covariance matrix 2
            * params = scale either 'linear' or anything else for log scale

        Outputs:
        ---------
            * a = the Wishart affinity between ğšº_1 and ğšº_2
        """
    
    if params=='linear':
        return 1/Wishart_distance(vhğšº_1, vhğšº_2, params)
    else:
        return -Wishart_distance(vhğšº_1, vhğšº_2, params)


def covariance_arithmetic_mean(ğ—_class, mean_parameters=None):
    """ Arithmetic mean as discribed in II.B. of:
        P. Formont, F. Pascal, G. Vasile, J. Ovarlez and L. Ferro-Famil, 
        "Statistical Classification for Heterogeneous Polarimetric SAR Images," 
        in IEEE Journal of Selected Topics in Signal Processing, 
        vol. 5, no. 3, pp. 567-576, June 2011.
        doi: 10.1109/JSTSP.2010.2101579
        ----------------------------------------------------------------------
        Inputs:
        --------
            * ğ—_class = array of shape (p, M) corresponding to 
                        samples in class
            * mean_parameters = unused here but needed for coherent coding

        Outputs:
        ---------
            * ğ› = the arithmetic mean
        """

    return np.mean(ğ—_class, axis=1)


# ----------------------------------------------------------------------------
# 2) Euclidean classifier: Euclidean distance + arithmetic mean
# ----------------------------------------------------------------------------
def covariance_Euclidean_distance(vhğšº_1, vhğšº_2, params='fro'):
    """ Euclidean distance between covariance matrices in parameters
        ----------------------------------------------------------------------
        Inputs:
        --------
            * vhğšº_1 = a (p,) numpy array corresponding to the vech 
                    of the covariance matrix 1
            * vhğšº_2 = a (p,) numpy array corresponding to the vech 
                    of the covariance matrix 2
            * params = order of the norm as described in:
            https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html

        Outputs:
        ---------
            * d = the Euclidean distance between ğšº_1 and ğšº_2
        """
    ğšº_1 = unvech(vhğšº_1)
    ğšº_2 = unvech(vhğšº_2)
    d = np.linalg.norm(ğšº_2-ğšº_1, params)
    return np.real(d)

# ----------------------------------------------------------------------------
# 3) Riemannian covariance classifier: Riemannian distance + mean
# ----------------------------------------------------------------------------
def Riemannian_distance_covariance(ğ±_1, ğ±_2, params=None):
    """ Riemannian distance on covariance parameters
        ----------------------------------------------------------------------
        Inputs:
        --------
            * ğ±_1 = a (p*(p+1)/2,) numpy array corresponding to the stack of vech 
                    of the covariance matrix for sample 1
            * ğ±_2 = a (p*(p+1)/2,) numpy array corresponding to the stack of vech 
                    of the covariance matrix for sample 2
            * params = unused here
        Outputs:
        ---------
            * d = the distance between samples
        """
    ğšº_1 = unvech(ğ±_1)
    ğšº_2 = unvech(ğ±_2)
    iğšº_1_sqm = invsqrtm(ğšº_1)
    d = np.linalg.norm( logm( iğšº_1_sqm @ ğšº_2 @ iğšº_1_sqm ) )**2

    return np.real(d)


def compute_J(ğ—_class, p, M, isqrtm_ğŒ, enable_multi=False, queue=None):
    """ A simple function to parallelise some part of the Riemannian mean"""

    M_subset = ğ—_class.shape[1]
    J = np.zeros((p, p), dtype=complex)
    #for index in tqdm(range(M_subset)):
    for index in range(M_subset):
        J += (1/M) * logm(isqrtm_ğŒ.conj().T @ unvech(ğ—_class[:, index]) @ isqrtm_ğŒ)

    if enable_multi:
        queue.put(J)
    else:
        return J

def wrapper_compute_J(ğ—_class, isqrtm_ğŒ, enable_multi=False, number_of_threads=4):

    (p, M) = ğ—_class.shape
    p = int(np.round(.5 * (-1 + np.sqrt(1 + 8 * p)))) # Size of matrices when unvech

    if enable_multi:        
        indexes_split = np.hstack([0, int(M / number_of_threads) * np.arange(1, number_of_threads), M])
        # Separate data in subsets to be treated in parallel
        ğ—_subsets = []
        for t in range(1, number_of_threads + 1):
            ğ—_subsets.append(ğ—_class[:, indexes_split[t - 1]:indexes_split[t]])
        queues = [Queue() for i in range(number_of_threads)]  # Serves to obtain result for each thread
        args = [(ğ—_subsets[i], p, M, isqrtm_ğŒ, True, queues[i]) for i in range(number_of_threads)]
        jobs = [Process(target=compute_J, args=a) for a in args]

        J = np.zeros((p, p), dtype=complex)
        # Starting parallel computation
        for j in jobs: j.start()
        # Obtaining result for each thread
        for q in queues: J += q.get()
        # Waiting for each thread to terminate
        for j in jobs: j.join()

    else:
        J = compute_J(ğ—_class, p, M, isqrtm_ğŒ)

    return J


def Riemannian_mean_covariance(ğ—_class, mean_parameters=None):
    """ Riemannian mean as discribed in section 3. of:
        P. Formont, J. P. Ovarlez, F. Pascal, G. Vasile and L. Ferro-Famil, 
        "On the extension of the product model in POLSAR processing for unsupervised 
        classification using information geometry of covariance matrices," 
        2011 IEEE International Geoscience and Remote Sensing Symposium, 
        Vancouver, BC, 2011, pp. 1361-1364.
        doi: 10.1109/IGARSS.2011.6049318
        ----------------------------------------------------------------------
        Inputs:
        --------
            * ğ—_class = array of shape (p*(p+1)/2, M) corresponding to 
                        samples in class
            * mean_parameters = (Ïµ, Ïµ_step, tol, iter_max, enable_multi, number_of_threads) where
                * Ïµ_start controls the speed of the gradient descent at first step
                * Ïµ_update is the step of in line search: Ïµ = Ïµ_start * Ïµ_update at each descending step
                * tol is the tolerance to stop the gradient descent
                * iter_max is the maximum number of iteration
                * enable_multi is a boolean to activate parrallel computation
                * number_of_threads is the number of threas for parrallel computation

        Outputs:
        ---------
            * ğ› = the vech of Riemannian mean
        """
    (p, M) = ğ—_class.shape
    p = int(np.round(.5 * (-1 + np.sqrt(1 + 8 * p)))) # Size of matrices when unvech
    (Ïµ_start, Ïµ_update, tol, iter_max, enable_multi, number_of_threads) = mean_parameters

    # Initialisation by doing explog geometric mean
    ğŒmean = np.zeros((p,p), dtype=complex)
    for index in range(M):
        ğŒmean += logm(unvech(ğ—_class[:,index]))
    ğŒmean = expm(ğŒmean/M)
    
    # Initialise criterions of convergence
    Î´ = np.finfo(np.float64).max
    criterion = np.finfo(np.float64).max
    Ïµ = Ïµ_start
    iteration = 0

    # Loop conditions
    while (criterion>tol) and (iteration<iter_max) and (Ïµ>tol):
        iteration = iteration + 1
        print("Riemannian mean over %d samples, iteration %d"%(M,iteration))

        # Computing needed terms
        sqrtm_ğŒ = sqrtm(ğŒmean)
        isqrtm_ğŒ = invsqrtm(ğŒmean)

        # Computing sum in the formula for the update
        J = wrapper_compute_J(ğ—_class, isqrtm_ğŒ, enable_multi=enable_multi, number_of_threads=number_of_threads)

        # Updating mean matrix
        ğŒmean = sqrtm_ğŒ.conj().T @ expm(Ïµ*J) @ sqrtm_ğŒ

        # Managing iterative algorithm
        criterion = np.linalg.norm(J, ord='fro')
        h = Ïµ * criterion
        if h<Î´:
            Ïµ = Ïµ_start * Ïµ_update
            Î´ = h
        else:
            Ïµ = .5 * Ïµ

    return vech(ğŒmean)


# ----------------------------------------------------------------------------
# 3) SIRV distance for covariance classifier + Mean = arithmetic mean
# ----------------------------------------------------------------------------
def compute_feature_SIRV_distance(ğ—, args):
    """ Serve to compute feature for Covariance only classification with SIRV distance as described in:
        G. Vasile, J.-P. Ovarlez, F. Pascal, and C. Tison, 
        â€œCoherency matrixestimation of heterogeneous clutter in high-resolution polarimetricSAR images,â€
        IEEE Trans. Geosci. Remote Sens., vol. 48, no. 4, pp.1809â€“1826, Apr. 2010.
        We concatenate the vech of Tyler, and the values of pixel in local windows
        The feature is just the vech of Tyler but we need the values of pixels for the SIRV distance.
        ----------------------------------------------------------------------
        Inputs:
        --------
            * ğ— = a (p, N) array where p is the dimension of data and N the number
                    of samples used for estimation
            * args = (Ïµ, iter_max) for Tyler estimator, where
                ** Ïµ = tolerance for convergence for Tyler
                ** iter_max = number of iterations max for Tyler

        Outputs:
        ---------
            * ğ± = the feature for classification
        """
    Ïµ, iter_max = args
    ğšº, Î´, iteration = tyler_estimator_covariance(np.squeeze(ğ—), Ïµ, iter_max)
    return list( np.hstack( [vech(ğšº), np.ravel(ğ—, order='F')]) )


def SIRV_distance(ğœ, ğ±, params):
    """ SIRV distance as defined in:
        G. Vasile, J.-P. Ovarlez, F. Pascal, and C. Tison, 
        â€œCoherency matrixestimation of heterogeneous clutter in high-resolution polarimetricSAR images,â€
        IEEE Trans. Geosci. Remote Sens., vol. 48, no. 4, pp.1809â€“1826, Apr. 2010.
        ----------------------------------------------------------------------
        Inputs:
        --------
            * ğœ = a (p*(p+1)/2 + N*p,) numpy array corresponding to the stack of vech 
                    of the of mean of class matrix and vector values for samples which are unused here
            * ğ± = a (p*(p+1)/2 + N*p,) numpy array corresponding to the stack of vech 
                    of the covariance matrix and vector values for samples
            * params = (p, N) where:
                ** p = dimension of vectors
                ** N = number of samples
        Outputs:
        ---------
            * d = the distance between samples and class mean
        """

    p, N = params
    ğŒğ“Œ = unvech(ğœ[:int(p*(p+1)/2)]) # Class mean matrix
    ğŒFP = unvech(ğ±[:int(p*(p+1)/2)]) # Tyler estimate on samples
    ğ¤ = ğ±[int(p*(p+1)/2):].reshape((p,N), order='F') # Samples in order to compute the distance

    ğ““_SIRV = np.log(np.abs(np.linalg.det(ğŒğ“Œ))) - np.log(np.abs(np.linalg.det(ğŒFP))) + (p/N) * \
            np.sum( np.diagonal(ğ¤.conj().T@np.linalg.inv(ğŒğ“Œ)@ğ¤) / np.diagonal(ğ¤.conj().T@np.linalg.inv(ğŒFP)@ğ¤) )
    return np.real(ğ““_SIRV)
